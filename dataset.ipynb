{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_mask(size):\n",
    "    mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int)\n",
    "    return mask == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BilingualDataset(Dataset):\n",
    "    def __init__(self, ds, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, seq_len) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ds = ds\n",
    "        self.tokenizer_src = tokenizer_src\n",
    "        self.tokenizer_tgt = tokenizer_tgt\n",
    "        self.src_lang = src_lang\n",
    "        self.tgt_lang = tgt_lang\n",
    "        self.seq_length = seq_len\n",
    "        \n",
    "        self.sos_token = torch.Tensor([tokenizer_src.token_to_id('[SOS]')], dtype= torch.int64)\n",
    "        self.eos_token = torch.Tensor([tokenizer_src.token_to_id('[EOS]')], dtype= torch.int64)\n",
    "        self.pad_token = torch.Tensor([tokenizer_src.token_to_id('[PAD]')], dtype= torch.int64)\n",
    "        \n",
    "    def __len__(self) :\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        src_target_pair = self.ds[index]\n",
    "        src_text = src_target_pair['translation'][self.src_lang]\n",
    "        tgt_text = src_target_pair['translation'][self.tgt_lang]\n",
    "        \n",
    "        encoder_input_token = self.tokenizer_src.encode(src_text).ids\n",
    "        decoder_input_token = self.tokenizer_tgt.encode(tgt_text).ids\n",
    "        \n",
    "        encode_num_padding_zeros = self.seq_length - len(encoder_input_token) - 2\n",
    "        decode_num_padding_zeros = self.seq_length - len(decoder_input_token) - 1\n",
    "        \n",
    "        if encode_num_padding_zeros < 0 or decode_num_padding_zeros < 0:\n",
    "            raise ValueError('Sentence is too long')\n",
    "        \n",
    "        encoder_input = torch.cat(\n",
    "            [\n",
    "                self.sos_token,\n",
    "                torch.tensor(encoder_input_token, dtype=torch.int64),\n",
    "                self.eos_token,\n",
    "                torch.tensor([self.pad_token] * encode_num_padding_zeros, dtype=torch.int64)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        decoder_input = torch.cat(\n",
    "            [\n",
    "                self.sos_token,\n",
    "                torch.tensor(decoder_input_token, dtype=torch.int64),\n",
    "                torch.tensor([self.pad_token] * decode_num_padding_zeros, dtype=torch.int64)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        label = torch.cat(\n",
    "            [\n",
    "                torch.tensor(decoder_input_token, dtype=torch.int64),\n",
    "                self.eos_token,\n",
    "                torch.tensor([self.pad_token] * decode_num_padding_zeros)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"encoder_input\": encoder_input,\n",
    "            \"decoder_input\": decoder_input,\n",
    "            \"encoder_mask\": (encoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int(), #(1,1,seq_length)\n",
    "            \"decoder_mask\": (decoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int() & causal_mask(decoder_input.shape(0)),\n",
    "            \"labels\": label,\n",
    "            \"src_text\": src_text,\n",
    "            \"tgt_text\": tgt_text\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
